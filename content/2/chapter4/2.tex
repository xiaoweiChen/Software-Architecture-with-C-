
There are many types of different software systems, each of them suited for different scenarios, built for different needs, and using different sets of assumptions. Writing and deploying a classical, standalone desktop application is nothing like writing and deploying a microservice that needs to communicate with many others over a network.

In this section, we'll go through the various models that you can use to deploy your software, the common mistakes that people should avoid when creating distributed systems, and some of the compromises people need to make to create such systems successfully

\subsubsubsection{4.2.1\hspace{0.2cm}Different service models and when to use them}

Let's first start with service models. When designing a bigger system, you need to decide how much of the infrastructure you will manage versus how much you can build upon existing building blocks. Sometimes, you might want to leverage existing software without the need to manually deploy an app or back up data, for example, by using Google Drive through its API as storage for your app. Other times, you can rely on an existing cloud platform such as Google's App Engine to deploy your solution without the need to worry about providing a language runtime or databases. If you can decide to deploy everything in your own way, you can either leverage an infrastructure from a cloud provider or use your company's one.

Let's discuss the different models and where each can be useful.

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{On-premises model}

The classical way, and the only way available in the pre-cloud era, is to just deploy everything on your own premises. You need to buy all the hardware and software required and make sure it will provide enough capacity for your  needs. If you're working for a startup company, this may be a big upfront cost. Along with the growth of your userbase, you need to buy and set up more resources so that your service can deal even with the occasional spikes in load. All this means you need to predict the growth of your solution and act proactively, as there's no way you could just automatically scale depending on the current load.

Even in the cloud era, deploying on-premises is still useful and often spotted in the wild. Sometimes you're dealing with data that shouldn't, or even can't, leave your company's premises, either due to data privacy issues or compliance ones. Other times, you need to have as little latency as possible and you need your own data center to do so. Sometimes you may calculate the costs and decide that in your case, on-premises will be cheaper than a cloud solution. Last, but not least, your company might just already have an existing data center that you can use.

Deploying on-premises doesn't mean you need to have a monolith system. Often, companies have their own private clouds deployed on-premises. This helps to cut costs by better utilization of the available infrastructure. You can also mix a private cloud solution with one of the other service models, which can be useful when you need that extra capacity from time to time. This is called a hybrid deployment and is offered by all major cloud providers as well as provided by OpenStack's Omni project.

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{Infrastructure as a Service (IaaS) model}

Speaking of other models, the most basic cloud service model is called Infrastructure as a Service (IaaS). It's also the most similar to on-premises: you can think of IaaS as a way to have a virtual data center. As the name suggests, the cloud provider offers you a slice of the infrastructure they host, which consists of three types of resources:

\begin{itemize}
\item 
Compute, such as virtual machines, containers, or bare-metal machines (excluding operating systems)

\item 
Networking, which aside from the network itself includes DNS servers, routing, and firewalls

\item 
Storage, including backup and recovery capabilities
\end{itemize}

It's still up to you to provide all the software: operating systems, middleware, and your applications.

IaaS can be used in scenarios ranging from hosting websites (might be cheaper than traditional web hosting), through storage (for example, Amazon's S3 and Glacier services), to high-performance computing and big data analysis (requires huge computing power). Some companies use it to quickly set up and purge test and development environments when needed.

Using IaaS instead of on-premises infrastructure can be a cheap way to test new ideas while saving you the time needed for configuration. 

If your service observes spikes in usage, for example, during the weekends, you might want to leverage your cloud's automatic scaling capabilities: scale up when needed and scale back down later to save money. 

IaaS solutions are offered by all the popular cloud service providers.

A similar concept, sometimes thought of as a subset of IaaS, is \textbf{Containers as a Service (CaaS)}. In CaaS, instead of bare-metal systems and virtual machines, the service provides you with containers and orchestration capabilities that you can use to build your own container clusters. CaaS offerings can be found with Google Cloud Platform and AWS, among others.

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{Platform as a Service (PaaS) model}

If the infrastructure itself is not enough for your needs, you can use the Platform as a Service (PaaS) model instead. In this model, the cloud service provider manages not only the infrastructure (just like in IaaS), but also the operating systems, any required middleware, and the runtime – the platform that you will deploy your software on.

Often a PaaS solution will provide you with app versioning capabilities, service monitoring and discovery, database management, business intelligence, and even development tools.

With PaaS, you're covered throughout the whole development pipeline: from building and testing to deploying, updating, and managing your service. However, PaaS solutions are more costly than IaaS offerings. On the other hand, with the whole platform provided, you can cut the costs and time to develop parts of your software and easily provide the same setup for development teams scattered around the globe.

All main cloud providers have their own offerings, for example, Google App Engine or Azure App Service. There are also independent ones, such as Heroku.

Aside from the more generic PaaS, there's also \textbf{Communications Platform as a Service (CPaaS)}, in which you're provided with the whole communications backend, including audio and video, which you can integrate into your solution. This technology allows you to easily provide video-enabled help desks or just integrate live chats into your apps.

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{Software as a Service (SaaS) model}

Sometimes you might not want to develop a software component on your own and just want to use an existing one. Software as a Service (SaaS) basically gives you a hosted application. With SaaS, you don't need to worry about either the infrastructure or the platform built upon it, and not even about the software itself. The provider is responsible for installing, running, updating, and maintaining the whole software stack, as well as backups, licensing, and scaling.

There's quite a variety to what software you can get in the SaaS model. Examples vary from office suites such as Office 365 and Google Docs to messaging software such as Slack, through \textbf{Customer Relationship Management (CRM)} systems, and span even to gaming solutions such as cloud gaming services, allowing you to play resource-hungry video games hosted on the cloud.

Usually, to access such services, all you need is a browser, so this can be a great step in providing remote work capabilities for your employees.

You can create your own SaaS applications and provide them to users either by deploying them however you like, or through means such as AWS Marketplace.

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{Function as a Service (FaaS) model and serverless architecture}

With the advent of cloud-native, another model that is growing in popularity is Function as a Service (FaaS). It can be helpful if you want to achieve a serverless architecture. With FaaS, you get a platform (similarly to PaaS) on which you can run short-lived applications, or functions.

With PaaS, you typically always need to have at least one instance of your service running, while in FaaS you can run them only when they're actually needed. Running your function can make the time to handle requests longer (measured in seconds; you need to launch the function after all). However, some of those requests can be cached to reduce both the latency and costs. Speaking about costs, FaaS can get way more expensive than PaaS if you run the functions for a long time, so you must do the math when designing your system.

If used correctly, FaaS abstracts away the servers from the developers, can reduce your costs, and can provide you with better scalability, as it can be based on events, not resources. This model is commonly used for running prescheduled or manually triggered tasks, processing batches or streams of data, and handling incoming, not-so-urgent requests. A few popular providers of FaaS are AWS Lambda, Azure Functions, and Google Cloud Functions.

Now that we've covered the common service models in the cloud, let's discuss some of the wrong assumptions people make when designing distributed systems.

\subsubsubsection{4.2.2\hspace{0.2cm}Avoiding the fallacies of distributed computing}

When people new to distributed computing begin their journey with designing such systems, they tend to forget or ignore a few aspects of such systems. Although they were first noticed back in the 90s, they remain current today.

The fallacies are discussed in the following sub-sections. Let's have a quick rundown on each of them.

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{The network is reliable}

Networking equipment is designed for long years of flawless operation. Despite that, many things can still cause packet loss, ranging from power outages through poor wireless networking signal, configuration errors, someone tripping over a cable, or even animals biting through wires. For instance, Google had to protect their underwater cables with Kevlar because they were being bitten by sharks (yes, really). You should always assume that data can get lost somewhere over the network. Even if that doesn't happen, software issues can still occur on the other side of the wire.

To fend off such issues, be sure you have a policy for automatically retrying failed network requests and a way to handle common networking issues. When retrying, try to not overload the other party and not commit the same transaction multiple times. You can use a message queue to store and retry sending for you.

Patterns such as circuit breaker, which we'll show later in this chapter, can also help. Oh, and be sure to not just wait infinitely, hogging up resources with each failed request.

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{Latency is zero}

Both the network and the services you're running have to take some time to respond even under normal conditions. Occasionally they'll have to take longer, especially when being under a bigger-than-average load. Sometimes instead of a few milliseconds, your requests can take seconds to complete.

Try to design your system so it doesn't wait on too many fine-grained remote calls, as each such call can add to your total processing time. Even in a local network, 10,000 requests for 1 record will be much slower than 1 request for 10,000 records. To reduce network latency, consider sending and handling requests in bulk. You can also try to hide the cost of small calls by doing other processing tasks while waiting for their results.

Other ways to deal with latency are to introduce caches, push the data in a publishersubscriber model instead of waiting for requests, or deploy closer to the customers, for example, by using \textbf{Content Delivery Networks} (\textbf{CDN}s).

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{Bandwidth is infinite}

When adding a new service to your architecture, make sure you take note of how much traffic it's going to use. Sometimes you might want to reduce the bandwidth by compressing the data or by introducing a throttling policy.

This fallacy also has to do with mobile devices. If the signal is weak, often the network will become the bottleneck. This means the amount of data a mobile app uses should generally be kept low. Using the \textit{Backends for Frontends} pattern described in \textit{Chapter 2, Architectural Styles}, can often help save precious bandwidth.

If your backend needs to transfer lots of data between some components, try to make sure such components are close together: don't run them in separate data centers. With databases, this often boils down to better replication. Patterns such as CQRS (discussed later in this chapter) are also handy.

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{The network is secure}

This is a dangerous fallacy. A chain is only as strong as its weakest link, and unfortunately, there are many links in distributed systems. Here are a few ways to make those links stronger:

\begin{itemize}
\item 
Be sure to always apply security patches to every component that you use, to your infrastructure, operating systems, and other components.

\item 
Train your personnel and try to protect your system from the human factor; sometimes it's a rogue employee that compromises a system.

\item 
If your system will be online, it will get attacked, and it's possible that a breach will happen at one point. Be sure to have a written plan on how to react to such events.

\item 
You might have heard about the defense in depth principle. It boils down to having different checks for different parts of your system (your infrastructure, your applications, and so on) so that when a breach happens, its range, and the associated damage, will be limited.

\item 
Use firewalls, certificates, encryption, and proper authentication.
\end{itemize}

For more on security, refer to \textit{Chapter 10, Security in Code and Deployment}.


\hspace*{\fill} \\ %插入空行
\noindent
\textbf{Topology doesn't change}

This one became especially true in the microservices era. Autoscaling and the emergence of the cattle, not pets approach to managing infrastructure mean that the topology will constantly change. This can affect latency and bandwidth, so some of this fallacy's outcomes are the same as the ones described earlier.

Fortunately, the mentioned approach also comes with guidelines on how to effectively manage your herd of servers. Relying on hostnames and DNS instead of hardcoding IPs is a step in the right direction, and service discovery, described later in this book, is another one. A third, even bigger, step is to always assume your instances can fail and automate reacting to such scenarios. Netflix's Chaos Monkey tool can also help you test your preparedness.

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{There is one administrator}

The knowledge about distributed systems, due to their nature, is often distributed itself. Different people are responsible for the development, configuration, deployment, and administration of such systems and their infrastructure. Different components are often upgraded by different people, not necessarily in sync. There's also the so-called bus factor, which in short is the risk factor for a key project member being hit by a bus.

How do we deal with all of this? The answer consists of a few parts. One of them is the DevOps culture. By facilitating close collaboration between development and operations, people share the knowledge about the system, thus reducing the bus factor. Introducing continuous delivery can help with upgrading the project and keeping it always up.

Try to model your system to be loosely coupled and backward compatible, so upgrades of components don't require other components to be upgraded too. An easy way to decouple is by introducing messaging between them, so consider adding a queue or two. It will help you with downtime during upgrades as well.

Finally, try to monitor your system and gather logs in a centralized place. Decentralization of your system shouldn't mean you now need to manually look at logs at a dozen different machines. The \textbf{ELK (Elasticsearch, Logstash, Kibana)} stack is invaluable for this. Grafana, Prometheus, Loki, and Jaeger are also very popular, especially with Kubernetes. If you're looking for something more lightweight than Logstash, consider Fluentd and Filebeat, especially if you're dealing with containers.

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{Transport cost is zero}

This fallacy is important for planning your project and its budget. Building and maintaining a network for a distributed system costs both time and money, regardless of whether you deploy on-premises or in the cloud – it's just a matter of when you pay the cost. Try to estimate the costs of the equipment, the data to be transferred (cloud providers charge for this), and the required manpower.

If you're relying on compression, be wary that while this reduces networking costs, it can increase the price for your compute. In general, using binary APIs such as gRPC-based will be cheaper (and faster) than JSON-based ones, and those are still cheaper than XML. If you send images, audio, or video, it's a must to estimate how much this will cost you.

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{The network is homogeneous}

Even if you plan what hardware to have and what software to run on your network, it's easy to end up with at least some heterogeneity. A slightly different configuration on some of the machines, a different communication protocol used by that legacy system that you need to integrate with, or different mobile phones sending requests to your system are just a few examples of this. Another one is extending your on-premises solution by using additional workers in the cloud.

Try to limit the number of protocols and formats used, strive to use standard ones, and avoid vendor lock-in to ensure your system can still communicate properly in such heterogeneous environments. Heterogeneity can also mean differences in resiliency. Try to use the circuit breaker pattern along with retries to handle this.

Now that we've discussed all the fallacies, let's discuss yet another pretty important aspect of distributed architectures.

\subsubsubsection{4.2.3\hspace{0.2cm}CAP theorem and eventual consistency}

To design successful systems that spread across more than one node, you need to know and use certain principles. One of them is the \textbf{CAP theorem}. It's about one of the most important choices you need to make when designing a distributed system and owes its name to the three properties a distributed system can have. They are as follows:

\begin{itemize}
\item 
\textbf{Consistency}: Every read would get you the data after the most recent write (or an error).

\item 
\textbf{Availability}: Every request will get a non-error response (without the guarantee that you'll get the most recent data).

\item 
\textbf{Partition tolerance}: Even if a network failure occurs between two nodes, the system as a whole will continue working.
\end{itemize}

In essence, the theorem states that you can pick at most two of those three properties for a distributed system.

As long as the system operates properly, it looks like all three of the properties can be satisfied. However, as we know from looking at the fallacies, the network is unreliable, so partitions will occur. In such cases, a distributed system should still operate properly. This means the theorem actually makes you choose between delivering partition tolerance and consistency (that is CP), or partition tolerance and availability (that is AP). Usually, the latter is the better choice. If you want to choose CA, you have to remove the network entirely and be left with a single-node system.

If under a partition, you decide to deliver consistency, you will have to either return an error or risk timeouts when waiting for the data to be consistent. If you choose availability over consistency, you risk returning stale data – the latest writes might be unable to propagate across the partition.

Both those approaches are suited for different needs. If your system requires atomic reads and writes, for instance, because a customer could lose their money, go with CP. If your system must continue operating under partitions, or you can allow eventual consistency, go with AP.

Okay, but what is eventual consistency? Let's discuss the different levels of consistency to understand this.

In a system offering strong consistency, each write is synchronously propagated. This means all reads will always see the latest writes, even at the cost of higher latency or lower availability. This is the type that relational DBMSes offer (based on ACID guarantees) and is best suited for systems that require transactions. 

In a system offering eventual consistency, on the other hand, you only guarantee that after a write, reads will eventually see the change. Usually, eventually means in a couple of milliseconds. This is due to the asynchronous nature of data replication in such systems, as opposed to the synchronous propagation from the previous paragraph. Instead of providing ACID guarantees, for example, using an RDBMS, here we have BASE semantics, often provided by NoSQL databases.

For a system to be asynchronous and eventually consistent (as AP systems often are), it's needed to have a way to solve state conflicts. A common way to do so is to exchange updates between instances and choose either the first or the last write as the accepted one.

Let's now discuss two related patterns that can help in achieving eventual consistency.

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{Sagas and compensating transactions}

The saga pattern is useful when you need to perform distributed transactions. Before the microservice era, if you had one host with one database, you could rely on the database engine to do the transaction for you. With multiple databases on one host, you  could use\textbf{ Two-Phase Commits (2PCs)} to do so. With 2PCs, you would have a coordinator, who would first tell all the databases to prepare, and once they all report being ready, it would tell them all to commit the transaction.

Now, as each microservice likely has its own database (and it should if you want scalability), and they're spanned all over your infrastructure, you can no longer rely on simple transactions and 2PCs (losing this ability often means you no longer want an RDBMS, as NoSQL databases can be much faster).

Instead, you can use the saga pattern. Let's demonstrate it in an example.

Imagine you want to create an online warehouse that tracks how much supply it has and allows payment by credit cards. To process an order, above all other services, you need three: one for processing the order, one for reserving the supplies, and one for charging the card.

Now, there are two ways the saga pattern can be implemented: choreography-based (also called event-based) and orchestration-based (also called command-based).

\hspace*{\fill} \\ %插入空行
\noindent
\textit{Choreography-based sagas}

In the first case, the first part of the saga would be the order processing service sending an event to the supply service. This one would do its part and send another event to the payment service. The payment service would then send yet another event back to the order service. This would complete the transaction (the saga), and the order could now be happily shipped.

If the order service would want to track the state of the transaction, it would simply need to listen to all those events as well.

Of course, sometimes the order would be impossible to complete, and a rollback would need to happen. In this case, each step of the saga would need to be rolled back separately and carefully, as other transactions could run in parallel, for example, modifying the supply state. Such rollbacks are called compensating transactions.

This way of implementing the saga pattern is pretty straightforward, but if there any many dependencies between the involved services it might be better to use the orchestration approach. Speaking of which, let's now say a few words about this second approach to sagas.

\hspace*{\fill} \\ %插入空行
\noindent
\textit{Orchestration-based sagas}

In this case, we'll need a message broker to handle communication between our services, and an orchestrator that would coordinate the saga. Our order service would send a request to the orchestrator, which would then send commands to both the supply and payment services. Each of those would then do their part and send replies back to the orchestrator, through a reply channel available at the broker. 

In this scenario, the orchestrator has all the logic needed to, well, orchestrate the transaction, and the services themselves don't need to be aware of any other services taking part in the saga.

If the orchestrator is sent a message that one of the services failed, for example, if the credit card has expired, it would then need to start the rollback. In our case, it would again use the broker to send an appropriate rollback command to specific services.

Okay, that's enough about eventual consistency for now. Let's now switch to other topics related to availability.



